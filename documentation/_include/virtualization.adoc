:sectnums:
:sectnumlevels: 3
:markup-in-source: verbatim,attributes,quotes
:imagesdir: ./_images
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]
:format_cmd_exec: source,options="nowrap",subs="{markup-in-source}",role="copy"
:format_cmd_output: bash,options="nowrap",subs="{markup-in-source}"
:format_plain: bash,options="nowrap"
ifeval::["%cloud_provider%" == "ec2"]
:format_cmd_exec: source,options="nowrap",subs="{markup-in-source}",role="execute"
endif::[]


:toc:
:toclevels: 1

= Virtualization Management

WARNING: This exercise depends on the work created by the ImageBuilder unit.  
If you have not completed that work, please do so before proceeding.

Provided your hardware is reasonably modern, chances are that it supports virtualization.  This unit introduces simple virtualization management using kvm and libvirt.  You will learn how to:

    * Install additional necessary software
    * Enable necessary system services and firewall ports
    * Use the command line to create and manage a virtual machine
    * Use the web console (cockpit) to create and manage a virtual machine

== Getting Started

For these exercises, you will be using the host `bastion` as user `root`.

Use `sudo` to elevate your privileges.

[{format_cmd_exec}]
----
[[ "$UID" == 0 ]] || sudo -i
----

Verify that you are on the right host for these exercises.

[{format_cmd_exec}]
----
workshop-virt-checkhost.sh
----

You are now ready to proceed with these exercises.

== Requirements

First we need to ensure the system being used supports either:

    * Intel VT-x and Intel 64 virtualization extensions
    * AMD-V and the AMD64 virtualization extensions

This is done with the following simple commands.

You can start by examining the CPU flags (capabilities) advertised by your system.

[{format_cmd_exec}]
----
grep -E 'svm|vmx' /proc/cpuinfo
----

[{format_cmd_output}]
----
flags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 
clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good
nopl xtopology cpuid tsc_known_freq pni pclmulqdq *vmx* ssse3 fma cx16 pcid sse4_1 sse4_2 
x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnow
prefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept
vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rds
eed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 arat pku os
pke avx512_vnni md_clear arch_capabilities
----

You are looking for either the Intel flag (vmx) or the AMD flag (svm).  

WARNING:  It could very well be that your environment does not support
native or nested virtualization.  This does not mean that this exercise
will not work, but it does mean that (if it does work) it will be VERY slow.

A more sophisticated command makes it a little easier to determine.

[{format_cmd_exec}]
----
if grep -qE 'svm|vmx' /proc/cpuinfo ; then echo 'Virt Supported' ; else echo 'WARNING: no hardware virtualization support detected'; fi
----

[{format_cmd_output}]
----
Virt Supported
----

After you install all the required software, there are some additional tools to provide more detailed reporting on system capabilities.

WARNING:  AGAIN ... It could very well be that your environment does not support 
native or nested virtualization.  This does not mean that this exercise 
will not work, but it does mean that (if it does work) it will be VERY slow.


== Installation and Configuration

NOTE: Please note that all software has been pre-installed and configured.  These steps are provided as reference material only.

System needs to be configure with access to the following repos:

  * rhel-9-baseos-rpms
  * rhel-9-appstream-rpms

Install the required packages.

[{format_cmd_exec}]
----
dnf install -y qemu-kvm libvirt virt-install libvirt-client libguestfs-tools cockpit-machines
----

Next we need to enable the various services.

[{format_cmd_exec}]
----
systemctl enable --now libvirtd
----

NOTE: The "enable --now" syntax was introduced in RHEL 8 and allows for permanently enabling as well as immediately starting services in a single command.

Finally check the service status.

[{format_cmd_exec}]
----
systemctl --no-pager status libvirtd
----

=== Verify Virtualization Host Status

One simple command checks various hardware and software configurations for support of virtualization.

[{format_cmd_exec}]
----
virt-host-validate
----

[{format_cmd_output}]
----
  QEMU: Checking for hardware virtualization                                 : PASS
  QEMU: Checking if device /dev/kvm exists                                   : PASS
  QEMU: Checking if device /dev/kvm is accessible                            : PASS
  QEMU: Checking if device /dev/vhost-net exists                             : PASS
  QEMU: Checking if device /dev/net/tun exists                               : PASS
  QEMU: Checking for cgroup 'cpu' controller support                         : PASS
  QEMU: Checking for cgroup 'cpuacct' controller support                     : PASS
  QEMU: Checking for cgroup 'cpuset' controller support                      : PASS
  QEMU: Checking for cgroup 'memory' controller support                      : PASS
  QEMU: Checking for cgroup 'devices' controller support                     : PASS
  QEMU: Checking for cgroup 'blkio' controller support                       : PASS
  QEMU: Checking for device assignment IOMMU support                         : WARN (No ACPI IVRS table found, IOMMU either disabled in BIOS or not supported by this hardware platform)
----



== Deploy A Virtual-Machine with 'virt-install'

Red Hat provides pre-made generic images of RHEL for use as virtual machines in a QCOW2 format.

However, in order to access them for download one needs to have an active Red Hat Enterprise Linux entitlement.  An alternative to downloading a qcow image is to make one.  

Fortunately, that's precisely what you did in the previous unit with Image Builder.

=== Locate your QCOW Image

In the previous exercise, you built a custom QCOW2 image using Image Builder.  The result of that work should be a vm image named vmguest.qcow2 

[{format_cmd_exec}]
----
ls /var/lib/libvirt/images
----

[{format_cmd_output}]
----
vmguest.qcow2
----

== Customize your QCOW Image

Now you need to do a few more things to your image:

    * set a hostname
    * set a root password
    * copy a simple HTML file
    * selinux relabel files in the guest
    * remove the cloud-init package

We will include a timer on this command so you can estimate how long this
will take.  On our AWS reference platform without virt support, this took
about 5 minutes.

[{format_cmd_exec}]
----
time virt-customize \
    -a /var/lib/libvirt/images/vmguest.qcow2 \
    --hostname vmguest \
    --root-password password:redhat \
    --ssh-inject root:file:/root/.ssh/id_rsa.pub \
    --copy-in /usr/local/etc/index.html:/var/www/html \
    --selinux-relabel \
    --run-command 'echo "PermitRootLogin yes" >> /etc/ssh/sshd_config.d/rootlogin.conf' \
    --uninstall cloud-init
----

[{format_cmd_output}]
----
[   0.0] Examining the guest ...
[  59.2] Setting a random seed
[  59.6] Setting the machine ID in /etc/machine-id
[  59.6] Setting the hostname: vmguest
[  60.4] Copying: /usr/local/etc/index.html to /var/www/html
[  60.7] Uninstalling packages: cloud-init
[  85.1] Setting passwords
[ 105.1] SELinux relabelling
[ 322.4] Finishing off

real    5m22.948s
user    0m0.037s
sys     0m0.057s
----


== VM Deployment

WARNING:  Please note that if your workshop environment did NOT show support for native or nested
virtualization, every step beyond this point will likely take a very long time.

It is now time to launch the VM

[{format_cmd_exec}]
----
virt-install \
   --import \
   --name vmguest \
   --memory 2048 \
   --cpu host \
   --vcpus 1 \
   --disk /var/lib/libvirt/images/vmguest.qcow2 \
   --graphics vnc \
   --noautoconsole\
   --os-variant rhel9.0
----

Give the VM a few moments to boot.

NOTE: If you explored the web-console exercise, you can use cockpit to 
access the VM's console and see what's going on.  Just be sure you 
selected administrative access.

== Virtual Machine Connectivity


WARNING: REMINDER: If your environment does not support
native or nested virtualization it does not mean that this exercise
will not work, but it does mean that (if it does work) it will be VERY slow.

To determine what IP address was assigned to the new host, we can using some options to the virsh utility

[{format_cmd_exec}]
----
virsh net-dhcp-leases default
----

The output will show us the clients MAC address and the IP address it was assigned via the libvirt integrated dnsmasq service.

[{format_cmd_output}]
----
 Expiry Time           MAC address         Protocol   IP address          Hostname   Client ID or DUID
-----------------------------------------------------------------------------------------------------------
 2021-11-13 11:19:33   52:54:00:63:85:76   ipv4       192.168.122.62/24   -          01:52:54:00:63:85:76
----

Another mechanism determine the ip address of the client is to use the 'domifaddr' option.

[{format_cmd_exec}]
----
virsh domifaddr vmguest
----

[{format_cmd_output}]
----
 Name       MAC address          Protocol     Address
-------------------------------------------------------------------------------
 vnet0      52:54:00:63:85:76    ipv4         192.168.122.62/24
----


WARNING: Before you proceed, empty data in the above commands is an indication that the virtual machine has 
not completed it's bootstrap.  Just give it a few more moments and try again.

Once we can see the network information, now it is time to connect to the host so 

[{format_cmd_exec}]
----
export VM_IP=$(virsh domifaddr vmguest | sed -e '1,2d' -e '$d' | awk '{ split($4,a,/\//) ; print a[1] }')
----

[{format_cmd_exec}]
----
curl $VM_IP
----

[{format_plain}]
----
*** Success !!! It Works  ***
----



== Virtual Machine Inspection

Now it is time to connect to the host and check out some it's characteristics.

[{format_cmd_exec}]
----
export VM_IP=$(virsh domifaddr vmguest | sed -e '1,2d' -e '$d' | awk '{ split($4,a,/\//) ; print a[1] }')
----

[{format_cmd_exec}]
----
ssh $VM_IP -i ~/.ssh/id_rsa -o "StrictHostKeyChecking no"
----

The password was set in the previous exercise with virt-customize command and is probably just 'redhat'.
However, since we injected the ssh key during virt-customize, you should not be prompted for a password.

The virtual machine is on a private network and not accessbile from the internet.  You will only 
be able to access it from the bastion via ssh, or from the webconsole.

Verify that the httpd daemon is running.

[{format_cmd_exec}]
----
systemctl --no-pager status httpd
----

Verifiy that the index.html is installed.

[{format_cmd_exec}]
----
ls /var/www/html/index.html
----

Exit back to the host

[{format_cmd_exec}]
----
exit
----

== Additional CLI Commands

Some additional simple virtual machine management commands

  * *virsh list* lists running virtual machines
  * *virsh list --all* lists all virtual machines regardless of state
  * *virsh start <vm-name>* starts a virtual machine named 
  * *virsh shutdown <vm-name>* performs a soft shutdown of the virtual machine
  * *virsh destroy <vm-name>* performs destructive cold stop the virtual machine

== Explore VM Management with 'Web-Console'

From the menu, select the Machines tab.  You will notice that the interface is still pretty rudimentary when compared with the Red Hat Virtualization Manager (RHVM), but one critical feature is available: the console!

Take some time to explore the capabilities of the Web-Console Machines webui.

== Virtual Machine Shutdown

WARN: It is IMPORTANT to shutdown the deployed VMs.  Leaving any VM running in this workshop environment can adversely impact other exercises.

Using either the CLI (or the Web-Console), be sure to shutdown the VM(s) you deployed to ensure additional workshop exercises perform reasonably.

[{format_cmd_exec}]
----
virsh list --all
----

[{format_cmd_exec}]
----
virsh shutdown vmguest
----

== Conclusion

This concludes the exercises related to virtualization.

Time to finish this unit and return the shell to it's home position.

[{format_cmd_exec}]
----
workshop-finish-exercise.sh
----


== Additional Resources

Cockpit Project Page

    * link:http://cockpit-project.org/blog/category/release.html[Cockpit Project]

Network Related Topics

    * link:https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/ch-configure_network_bridging[Configure Network Bridging]

    * link:http://blog.leifmadsen.com/blog/2016/12/01/create-network-bridge-with-nmcli-for-libvirt/[Create Network Bridge with nmcli]

[discrete]
== End of Unit

ifdef::env-github[]
link:../RHEL9-Workshop.adoc#toc[Return to TOC]
endif::[]

////
Always end files with a blank line to avoid include problems.
////
